{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with open ('train_2008.csv' ,'r') as dest_f:\n",
    "    data_iter = csv.reader(dest_f, delimiter = ',', quotechar = '\"') \n",
    "    data = [data for data in data_iter] \n",
    "    data_array = np.asarray(data)\n",
    "    \n",
    "\n",
    "\n",
    "shape = data_array.shape\n",
    "identity = data_array[:,0]\n",
    "y = np.array(data_array[1:,shape[1]-1],'f')\n",
    "X = np.array(data_array[1:,1:382],'f') # do not consider the first row since it's identity number.\n",
    "\n",
    "t_out = [0, 1, 11, 13, 15, 46, 57, 128, 129, 130, 134, 135, 136, 253, 257]\n",
    "\n",
    "X1 = np.delete(X, t_out, 1)\n",
    "\n",
    "Xinfo = np.zeros((2,381))\n",
    "for j in range(381):\n",
    "    Xinfo[0,j] = np.mean(X[:,j])\n",
    "    Xinfo[1,j] = np.std(X[:,j])\n",
    "    \n",
    "#Compute mean and std of every column of X1,X2,X_T\n",
    "Xinfo = np.zeros((2,366))\n",
    "for j in range(366):\n",
    "    Xinfo[0,j] = np.mean(X1[:,j])\n",
    "    Xinfo[1,j] = np.std(X1[:,j])\n",
    "    \n",
    "#normalize every column of X1,X2,X_T apart from first one\n",
    "for j in range(366):\n",
    "    X1[:,j] = (X1[:,j] - Xinfo[0,j]) / Xinfo[1,j]\n",
    "#    X_T[:,j] = (X_T[:,j] - Xinfo[0,j]) / Xinfo[1,j]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.10000000e+01   2.00800000e+03   1.51661587e+00   1.75470123e+02\n",
      "    6.29378203e-03   1.25286472e+00   1.20828247e+00   1.03094316e+00\n",
      "   -8.35140049e-01   9.17871535e-01   8.99508286e+00  -1.00000000e+00\n",
      "   -9.99860823e-01  -1.00000000e+00   2.16301740e+07   1.00000000e+00\n",
      "    2.83054733e+00   2.64199662e+00   4.47848225e+00   1.29947269e+00\n",
      "    4.87760365e-01   1.83965552e+00   8.40138906e+04   1.84857810e+00\n",
      "   -6.75321281e-01  -8.98789167e-01  -9.97030914e-01  -9.99768019e-01\n",
      "    2.56064153e+00   5.27473373e+01   2.84380131e+01   2.49663574e+04\n",
      "    2.74697304e+01   2.41303921e+00   1.24287498e+00   1.00932471e-01\n",
      "    3.37598777e+00   1.18402786e+02   2.87537694e+00  -7.42836356e-01\n",
      "    4.78741417e+01   4.42575030e-02   2.69543982e+00   4.44693595e-01\n",
      "    1.52592516e+00   1.88705218e+00   2.00000000e+00   4.03623314e+01\n",
      "    1.32968903e+00  -7.81882584e-01   8.78434086e+00   1.62432158e+00\n",
      "    7.89830983e-01   1.29130781e+00   1.41840506e+00   1.92766011e+00\n",
      "    3.13455081e+00   2.00000000e+00   7.05519485e+01   7.86733551e+01\n",
      "    7.90212326e+01   1.20464838e+00   5.65976463e-02   6.31094694e-01\n",
      "    1.45409560e+00   2.64842963e+00   1.60816181e+00  -9.03845847e-01\n",
      "   -9.86299038e-01   1.15669504e-01  -9.86113489e-01  -6.06074214e-01\n",
      "   -9.49402332e-01  -7.39619911e-01  -9.27892148e-01  -4.71600652e-01\n",
      "   -9.61897075e-01  -9.92592812e-01  -5.32574594e-01  -6.21321559e-01\n",
      "   -8.55505884e-01  -9.53794062e-01   8.74897540e-01  -8.67103755e-01\n",
      "    2.24131165e+01  -4.75420237e-01  -8.73366654e-01   2.26730022e+01\n",
      "   -6.80548012e-01  -9.06722128e-01  -6.58929586e-01  -5.62466145e-01\n",
      "    6.10450447e-01   1.46937385e-01   6.54661596e-01  -5.20760179e-01\n",
      "    2.29924850e+01  -4.11987573e-01   2.35383110e+01  -9.64958966e-01\n",
      "    8.78206789e-01   2.72748089e+00   2.71554279e+00  -4.91100550e-01\n",
      "    8.24207067e-01   1.48834801e+00   2.58051252e+00   9.19649899e-01\n",
      "   -9.59500194e-01  -9.67819750e-01  -9.90242302e-01  -9.99180436e-01\n",
      "   -9.87505198e-01  -9.64355826e-01  -9.89144385e-01  -9.81319666e-01\n",
      "   -9.87799048e-01  -9.97061849e-01  -6.37512207e-01  -8.28815341e-01\n",
      "   -8.39346170e-01  -8.97041738e-01  -9.47825015e-01  -9.74036217e-01\n",
      "   -9.88309324e-01  -9.95407224e-01  -9.99520600e-01  -9.99938130e-01\n",
      "   -1.00000000e+00  -1.00000000e+00  -1.00000000e+00  -9.72474396e-01\n",
      "   -9.98994827e-01  -9.99953628e-01  -1.00000000e+00  -1.00000000e+00\n",
      "   -1.00000000e+00  -9.30907547e-01  -9.95716512e-01  -9.04247940e-01\n",
      "   -9.44469333e-01  -9.19015884e-01  -2.59003818e-01  -9.18675661e-01\n",
      "   -7.26290047e-01  -8.75608861e-01  -9.59020853e-01  -9.76634145e-01\n",
      "   -9.86561954e-01  -9.90350544e-01  -9.84721720e-01  -9.96690750e-01\n",
      "   -5.22755027e-01  -9.95623708e-01  -9.98515487e-01  -9.17036533e-01\n",
      "   -9.52479601e-01  -9.38902378e-01  -9.98701036e-01  -9.79665041e-01\n",
      "   -9.41206515e-01  -6.49001837e-01  -9.14701462e-01  -7.06063390e-01\n",
      "    1.32155502e+00  -9.76262987e-01   1.10803194e+01   2.00204134e+00\n",
      "    3.91884565e-01   4.78049070e-01   2.26189566e+00  -9.21954036e-01\n",
      "    3.07111830e-01   1.63492978e+00  -2.23359674e-01  -8.37366819e-01\n",
      "    7.80691862e-01   2.79187226e+00  -5.33193126e-02  -9.88463998e-01\n",
      "   -8.75577986e-01  -9.96149480e-01  -1.16117962e-01   2.80776918e-01\n",
      "   -1.48066252e-01   2.48585820e+00   1.97074246e+00  -9.26191092e-01\n",
      "   -9.55989897e-01   1.79748559e+00   7.19377756e-01   6.96553111e-01\n",
      "    6.83857322e-01   1.03876781e+00   2.28235412e+00  -9.36134338e-01\n",
      "    3.24771523e-01   4.16594267e+00  -9.23021019e-01   2.05345688e+01\n",
      "   -6.66599631e-01   8.08944321e+00  -8.70490372e-01   2.48828620e-01\n",
      "    4.98096418e+00  -9.10062313e-01   2.41506481e+00  -9.55402315e-01\n",
      "    1.46295643e+00  -6.10976219e-02   2.44405955e-01   3.19730312e-01\n",
      "    1.40829176e-01  -5.97383499e-01  -4.26987499e-01  -7.81944394e-01\n",
      "   -6.59579098e-01  -9.72165108e-01   3.61870804e+01   9.23344040e+01\n",
      "    1.29521484e+02   1.54638372e-04   1.19436502e+00   1.16730352e+04\n",
      "    2.47421395e-03   1.78681183e+02   2.17113829e+00   3.09276766e-05\n",
      "    9.08763349e-01  -5.97120643e-01  -6.38223529e-01  -8.22954535e-01\n",
      "   -9.45536375e-01  -5.83234131e-01  -7.97423720e-01  -3.73111486e-01\n",
      "   -7.25470483e-01  -8.92062426e-01  -8.55243027e-01  -6.97326303e-01\n",
      "    2.18696680e+07   2.21151540e+07   2.18901320e+07   2.20077100e+07\n",
      "    2.20179160e+07   1.06623161e+00   1.75468162e-01  -8.23634923e-01\n",
      "   -8.95062387e-01   6.21336997e-02   4.14430872e-02   6.27058625e-01\n",
      "    9.80979502e-01   0.00000000e+00  -7.31748819e-01   8.39686394e-02\n",
      "    4.48921394e+01   0.00000000e+00   1.26324087e-01   4.42806989e-01\n",
      "    4.48451284e-03   1.00221133e+00   7.42264241e-02   2.16184452e-01\n",
      "    6.37914240e-01  -9.21149909e-01  -6.74965620e-01  -8.40969920e-01\n",
      "    3.17936502e-02   1.90205208e-03  -5.33610642e-01   2.66024411e-01\n",
      "    4.23972040e-01  -2.90534586e-01   2.39302889e-01  -2.71111995e-01\n",
      "    2.43864715e-01   1.59860516e+00  -2.55679101e-01   2.65359461e-01\n",
      "    2.81472772e-01   2.72612005e-01  -1.19164333e-01   2.74065584e-01\n",
      "   -2.57225484e-01   4.93497461e-01   2.69596547e-01  -9.95144367e-01\n",
      "   -9.95144367e-01  -9.93211389e-01  -9.93845403e-01  -9.65546548e-01\n",
      "   -9.65268195e-01  -9.61696088e-01  -9.43216801e-01  -9.58247662e-01\n",
      "   -9.28866327e-01  -9.59067225e-01  -4.19935971e-01  -3.36276621e-01\n",
      "   -3.63462031e-01  -3.54740441e-01  -3.59534234e-01  -3.53982717e-01\n",
      "   -3.54415685e-01  -3.56673419e-01  -3.61204326e-01  -3.49590987e-01\n",
      "   -3.60137314e-01   2.74328478e-02   1.87251613e-01   2.22710192e-01\n",
      "   -9.73989844e-01  -9.74237263e-01  -9.75196004e-01  -3.63709480e-01\n",
      "   -6.48305953e-01  -1.64597094e-01  -6.10867977e-01  -6.19635999e-01\n",
      "   -7.42820919e-01  -7.15790153e-01  -2.60302782e-01  -4.02044326e-01\n",
      "   -6.97743833e-01  -6.72599614e-01  -4.13704067e-01  -3.69214594e-01\n",
      "   -4.22472060e-01  -8.85737717e-01  -8.29866886e-01  -8.33021462e-01\n",
      "    3.35661562e+04   1.62432158e+00  -3.49219859e-01  -8.09841216e-01\n",
      "    1.03097409e-01  -4.83260393e-01  -8.88737679e-01  -7.76284635e-01\n",
      "    9.25232351e-01   1.02413905e+00   9.44051862e-01   9.14562285e-01\n",
      "    1.00180924e+00   9.86809373e-01   2.20029980e+07   4.23967822e+03\n",
      "    2.82239136e+03   6.40906677e+01   3.79596863e+01   7.54576540e+00\n",
      "   -8.68217170e-01  -3.98101032e-01  -8.98170650e-01  -9.74902213e-01\n",
      "   -9.94139194e-01   4.30667885e-02  -8.17681372e-01  -7.29521990e-01\n",
      "   -8.48284304e-01  -7.94655681e-01  -8.24933887e-01   3.22288818e+01\n",
      "    3.07662029e+01   1.14027250e+00   1.18406606e+00   2.60873389e+00\n",
      "    1.96228373e+00   1.97985065e+00   1.96248472e+00   1.92138183e+00\n",
      "    1.97966504e+00   1.95827854e+00   1.86821723e+00   4.20709163e-01\n",
      "    4.32214260e-01   4.59786296e-01   4.45961624e-01   4.45884287e-01\n",
      "    4.57002789e-01]\n",
      " [  0.00000000e+00   0.00000000e+00   8.38616848e-01   6.67400208e+01\n",
      "    7.90833235e-02   4.62775439e-01   9.26678061e-01   1.73163697e-01\n",
      "    6.53838217e-01   2.74672955e-01   6.08850479e+00   0.00000000e+00\n",
      "    1.80200208e-02   0.00000000e+00   1.18745310e+07   0.00000000e+00\n",
      "    1.48306108e+00   2.29331517e+00   2.29831314e+00   9.89471078e-01\n",
      "    8.15546513e-01   7.99531162e-01   9.99910889e+02   3.63684565e-01\n",
      "    8.45395088e-01   5.47898591e-01   1.11740619e-01   3.40548716e-02\n",
      "    1.06690049e+00   2.62510471e+01   1.56907444e+01   2.16482754e+04\n",
      "    6.60975342e+01   1.02577639e+00   4.47835654e-01   4.54090446e-01\n",
      "    2.57320857e+00   2.04442245e+02   2.95399737e+00   7.99830735e-01\n",
      "    1.75576744e+01   2.05666661e-01   2.10388899e+00   1.35491276e+00\n",
      "    4.99327421e-01   3.16529036e-01   0.00000000e+00   2.52989078e+00\n",
      "    1.17602718e+00   8.66990924e-01   1.23154366e+00   8.81502390e-01\n",
      "    4.62899715e-01   1.00167906e+00   9.22937393e-01   2.59049743e-01\n",
      "    2.56408811e+00   0.00000000e+00   5.47163734e+01   6.67078552e+01\n",
      "    6.73280487e+01   7.37299681e-01   1.00297892e+00   2.59498858e+00\n",
      "    5.02279282e-01   2.24404502e+00   8.91800642e-01   5.17139614e-01\n",
      "    1.79770052e-01   1.42621684e+00   1.82318360e-01   1.00905275e+00\n",
      "    3.76042753e-01   6.76691115e-01   3.82086873e-01   1.13981926e+00\n",
      "    2.87311196e-01   1.40109256e-01   1.09552801e+00   9.93965805e-01\n",
      "    1.17176437e+00   3.45424384e-01   1.42262959e+00   6.32591128e-01\n",
      "    2.16946297e+01   3.41957164e+00   5.30365169e-01   2.22979221e+01\n",
      "    9.28254783e-01   7.29664147e-01   1.29532945e+00   1.71488380e+00\n",
      "    1.42946088e+00   4.28583431e+00   1.45782554e+00   2.63266706e+00\n",
      "    2.14120235e+01   3.56352544e+00   2.19898109e+01   2.66087711e-01\n",
      "    1.42186213e+00   2.83536315e+00   2.85904884e+00   1.27471709e+00\n",
      "    1.43549395e+00   1.93939114e+00   2.83703470e+00   1.43933940e+00\n",
      "    3.38756710e-01   3.02770764e-01   1.39854640e-01   5.51878996e-02\n",
      "    1.82164550e-01   8.36825788e-01   1.58197209e-01   2.66982287e-01\n",
      "    1.87744141e-01   1.06932715e-01   9.49918211e-01   1.09398019e+00\n",
      "    1.11728835e+00   9.23375249e-01   6.76122367e-01   4.92123365e-01\n",
      "    3.37160468e-01   2.45063066e-01   6.42542988e-02   1.57295112e-02\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   5.89192510e-01\n",
      "    1.00636981e-01   1.17971338e-02   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   3.66775781e-01   1.35984808e-01   5.53885102e-01\n",
      "    3.87927443e-01   4.41602409e-01   5.93799782e+00   4.49488521e-01\n",
      "    8.55200171e-01   1.09103894e+00   3.20229530e-01   2.45254099e-01\n",
      "    1.96986660e-01   1.54718131e-01   1.82969227e-01   1.06196269e-01\n",
      "    1.46220720e+00   1.21062085e-01   6.67186677e-02   6.30657136e-01\n",
      "    3.68115664e-01   4.13998783e-01   6.24115430e-02   3.56100351e-01\n",
      "    4.00188386e-01   1.09640908e+00   5.74232578e-01   2.81621671e+00\n",
      "    4.67073232e-01   2.69436419e-01   8.73887825e+00   1.38561332e+00\n",
      "    9.79721248e-01   1.06533861e+00   2.77245831e+00   6.32141352e-01\n",
      "    3.52434373e+00   6.41868496e+00   5.99226856e+00   8.60906482e-01\n",
      "    6.90177202e-01   2.52565908e+00   1.38125610e+00   1.84588566e-01\n",
      "    8.40495586e-01   1.06976077e-01   1.00464427e+00   1.48133874e+00\n",
      "    9.96097565e-01   2.56828094e+00   2.23778105e+00   6.79712176e-01\n",
      "    4.52666938e-01   2.24356890e+00   1.97801542e+00   1.97632551e+00\n",
      "    4.64969367e-01   1.39072680e+00   2.31962633e+00   5.74995995e-01\n",
      "    1.10933757e+00   3.70096350e+00   7.98819184e-01   1.89184723e+01\n",
      "    3.62770581e+00   8.35588837e+00   1.42782915e+00   9.68547583e-01\n",
      "    4.82486153e+00   9.58337963e-01   3.21970439e+00   5.01831174e-01\n",
      "    2.19726300e+00   9.98131752e-01   9.69672918e-01   1.01073802e+00\n",
      "    3.47845227e-01   1.00299919e+00   1.64462161e+00   7.56456792e-01\n",
      "    8.60954821e-01   5.04139376e+00   2.95420624e+02   4.21366180e+02\n",
      "    5.07819946e+02   1.24344062e-02   8.96621895e+00   3.66675625e+04\n",
      "    4.96799052e-02   2.82835474e+03   4.40403534e+02   5.56117948e-03\n",
      "    9.81003094e+00   1.00354862e+00   9.75025237e-01   7.11646616e-01\n",
      "    3.93283695e-01   1.36836946e+00   6.49338841e-01   1.17044210e+00\n",
      "    8.04168224e-01   4.72684592e-01   6.31049573e-01   8.78158510e-01\n",
      "    1.20653660e+07   2.00217040e+07   4.52197760e+07   1.22259660e+07\n",
      "    1.22744020e+07   3.03884721e+00   1.23431265e+00   4.65115279e-01\n",
      "    3.73721480e-01   1.59487355e+00   1.19721615e+00   5.04778290e+00\n",
      "    1.33317697e+00   0.00000000e+00   3.39078903e+00   9.14621413e-01\n",
      "    1.46698999e+01   0.00000000e+00   2.29438806e+00   7.29620516e-01\n",
      "    2.11719215e-01   2.32782197e+00   9.13078785e-01   2.71195889e+00\n",
      "    3.96535945e+00   1.25072193e+00   3.71430278e+00   1.94673884e+00\n",
      "    8.55392754e-01   2.79249907e-01   7.38012552e-01   1.07482576e+00\n",
      "    2.73315382e+00   1.16584766e+00   9.86398220e-01   1.88448501e+00\n",
      "    1.01639068e+00   4.94529057e+00   1.29022908e+00   2.12613678e+00\n",
      "    1.38704610e+00   1.84668815e+00   3.04345989e+00   1.56134808e+00\n",
      "    1.22425747e+00   3.53544354e+00   1.03083014e+00   6.95130825e-02\n",
      "    6.95130825e-02   2.98760027e-01   2.48941973e-01   1.83152229e-01\n",
      "    1.95832074e-01   4.56500322e-01   6.89815462e-01   5.94993889e-01\n",
      "    1.26907039e+00   5.70248842e-01   1.44189274e+00   1.55028355e+00\n",
      "    1.11664605e+00   1.15776050e+00   9.42784846e-01   1.06036568e+00\n",
      "    1.12410605e+00   9.61104512e-01   1.23870873e+00   1.19000554e+00\n",
      "    1.27465713e+00   3.18933463e+00   4.09295464e+00   4.33638334e+00\n",
      "    7.19364882e-01   6.78691685e-01   6.40200675e-01   4.48319006e+00\n",
      "    1.75795126e+00   5.15507126e+00   1.64802134e+00   2.24189091e+00\n",
      "    9.65547323e-01   1.15383542e+00   5.09108448e+00   3.84764099e+00\n",
      "    2.68266368e+00   2.79206634e+00   9.02924061e-01   1.05056870e+00\n",
      "    1.29356551e+00   5.79449654e-01   6.50099754e-01   5.15174985e-01\n",
      "    1.92064531e+04   8.81502390e-01   9.77743924e-01   1.18239760e+00\n",
      "    1.78045487e+00   1.08977139e+00   5.07089734e-01   8.26128900e-01\n",
      "    3.23562312e+00   1.38097155e+00   2.79321623e+00   2.03831172e+00\n",
      "    1.40869606e+00   1.41517413e+00   1.22316570e+07   3.64026953e+03\n",
      "    2.87536426e+03   7.03061523e+02   4.49555634e+02   7.47634268e+00\n",
      "    1.43750358e+00   1.79444242e+00   7.40196407e-01   3.58998209e-01\n",
      "    1.84813946e-01   1.15126956e+00   6.98713481e-01   8.61637890e-01\n",
      "    5.60178697e-01   6.20974958e-01   7.09525526e-01   2.36310368e+01\n",
      "    2.40278244e+01   3.20288992e+00   3.69476151e+00   8.91647530e+00\n",
      "    1.90509275e-01   1.40511140e-01   1.90020710e-01   2.69141853e-01\n",
      "    1.41143337e-01   1.99951887e-01   3.38254511e-01   4.19249773e+00\n",
      "    4.24768114e+00   4.38052368e+00   4.31427288e+00   4.31352663e+00\n",
      "    4.36655903e+00]]\n",
      "(64667, 381)\n"
     ]
    }
   ],
   "source": [
    "print(Xinfo)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# divide the training set and test set. \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1, y, test_size=0.25)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf = GradientBoostingClassifier(n_estimators=30, learning_rate=1)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "print(clf.score(X_train,y_train))\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf_ada = AdaBoostClassifier(n_estimators=50, learning_rate=1)\n",
    "clf_ada = clf_ada.fit(X_train, y_train)\n",
    "print(clf_ada.score(X_train,y_train))\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf_ada2 = AdaBoostClassifier(n_estimators=300, learning_rate=1)\n",
    "clf_ada2 = clf_ada2.fit(X_train, y_train)\n",
    "print(clf_ada2.score(X_train,y_train))\n",
    "\n",
    "\n",
    "print(clf.score(X_test,y_test))\n",
    "print(clf_ada.score(X_test,y_test))\n",
    "print(clf_ada2.score(X_test,y_test))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-f009bdf1b6fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdaBoostClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdaBoostClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Gahye/anaconda/lib/python3.5/site-packages/sklearn/ensemble/weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m         \u001b[0;31m# Fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAdaBoostClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Gahye/anaconda/lib/python3.5/site-packages/sklearn/ensemble/weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                 \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m                 random_state)\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0;31m# Early termination\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Gahye/anaconda/lib/python3.5/site-packages/sklearn/ensemble/weight_boosting.py\u001b[0m in \u001b[0;36m_boost\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    469\u001b[0m         \"\"\"\n\u001b[1;32m    470\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithm\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'SAMME.R'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_boost_real\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miboost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# elif self.algorithm == \"SAMME\":\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Gahye/anaconda/lib/python3.5/site-packages/sklearn/ensemble/weight_boosting.py\u001b[0m in \u001b[0;36m_boost_real\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    479\u001b[0m         \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 481\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m         \u001b[0my_predict_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Gahye/anaconda/lib/python3.5/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    737\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 739\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    740\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Gahye/anaconda/lib/python3.5/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    348\u001b[0m                                            self.min_impurity_split)\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "dense_130 (Dense)                (None, 100)           36700       dense_input_12[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dropout_121 (Dropout)            (None, 100)           0           dense_130[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_131 (Dense)                (None, 80)            8080        dropout_121[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dropout_122 (Dropout)            (None, 80)            0           dense_131[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_132 (Dense)                (None, 50)            4050        dropout_122[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dropout_123 (Dropout)            (None, 50)            0           dense_132[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_133 (Dense)                (None, 40)            2040        dropout_123[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dropout_124 (Dropout)            (None, 40)            0           dense_133[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_134 (Dense)                (None, 30)            1230        dropout_124[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dropout_125 (Dropout)            (None, 30)            0           dense_134[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_135 (Dense)                (None, 30)            930         dropout_125[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dropout_126 (Dropout)            (None, 30)            0           dense_135[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_136 (Dense)                (None, 30)            930         dropout_126[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dropout_127 (Dropout)            (None, 30)            0           dense_136[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_137 (Dense)                (None, 30)            930         dropout_127[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dropout_128 (Dropout)            (None, 30)            0           dense_137[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_138 (Dense)                (None, 30)            930         dropout_128[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dropout_129 (Dropout)            (None, 30)            0           dense_138[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_139 (Dense)                (None, 30)            930         dropout_129[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dropout_130 (Dropout)            (None, 30)            0           dense_139[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_140 (Dense)                (None, 30)            930         dropout_130[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dropout_131 (Dropout)            (None, 30)            0           dense_140[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_141 (Dense)                (None, 30)            930         dropout_131[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dropout_132 (Dropout)            (None, 30)            0           dense_141[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_142 (Dense)                (None, 30)            930         dropout_132[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dropout_133 (Dropout)            (None, 30)            0           dense_142[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_143 (Dense)                (None, 30)            930         dropout_133[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dropout_134 (Dropout)            (None, 30)            0           dense_143[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_144 (Dense)                (None, 30)            930         dropout_134[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dropout_135 (Dropout)            (None, 30)            0           dense_144[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_145 (Dense)                (None, 30)            930         dropout_135[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dropout_136 (Dropout)            (None, 30)            0           dense_145[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_146 (Dense)                (None, 1)             31          dropout_136[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "activation_10 (Activation)       (None, 1)             0           dense_146[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 62,361\n",
      "Trainable params: 62,361\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Epoch 1/2\n",
      "64667/64667 [==============================] - 107s - loss: -4.0715 - acc: 0.7446   \n",
      "Epoch 2/2\n",
      "64667/64667 [==============================] - 93s - loss: -4.0715 - acc: 0.7446    \n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'History' object has no attribute 'evaluate'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-0f1a01f9601f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;31m## Printing the accuracy of our model,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;31m## according to the loss function specified in model.compile above\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test score:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test accuracy:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'History' object has no attribute 'evaluate'"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import tensorflow as tf \n",
    "import keras\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten, Dropout\n",
    "\n",
    "\n",
    "## 2(C)\n",
    "## Create your own model here given the constraints in the problem\n",
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim=366, init = 'glorot_uniform'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(80, init = 'glorot_uniform'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(50, init = 'glorot_uniform'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "\n",
    "model.add(Dense(40, init = 'glorot_uniform'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(30, init = 'glorot_uniform'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(30, init = 'glorot_uniform'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(30, init = 'glorot_uniform'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(30, init = 'glorot_uniform'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(30, init = 'glorot_uniform'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(30, init = 'glorot_uniform'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(30, init = 'glorot_uniform'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(30, init = 'glorot_uniform'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(30, init = 'glorot_uniform'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(30, init = 'glorot_uniform'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(30, init = 'glorot_uniform'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(30, init = 'glorot_uniform'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.add(Dense(1, init='uniform'))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "## Printing a summary of the layers and weights in your model\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='binary_crossentropy',  optimizer ='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "model.optimizer.lr.assign(0.05)\n",
    "\n",
    "model = model.fit(X1, y, batch_size=10, nb_epoch=2,  verbose=1)\n",
    "\n",
    "## Printing the accuracy of our model, \n",
    "## according to the loss function specified in model.compile above\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "If no scoring is specified, the estimator passed should have a 'score' method. The estimator <keras.models.Sequential object at 0x122c0c400> does not.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-580ce84d72d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mkfold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkfold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Results: %.2f%% (%.2f%%)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Gahye/anaconda/lib/python3.5/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0mcv_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m     \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m     \u001b[0;31m# We clone the estimator to make sure that all the folds are\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;31m# independent, and that it is pickle-able.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Gahye/anaconda/lib/python3.5/site-packages/sklearn/metrics/scorer.py\u001b[0m in \u001b[0;36mcheck_scoring\u001b[0;34m(estimator, scoring, allow_none)\u001b[0m\n\u001b[1;32m    271\u001b[0m         raise TypeError(\n\u001b[1;32m    272\u001b[0m             \u001b[0;34m\"If no scoring is specified, the estimator passed should \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m             \"have a 'score' method. The estimator %r does not.\" % estimator)\n\u001b[0m\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: If no scoring is specified, the estimator passed should have a 'score' method. The estimator <keras.models.Sequential object at 0x122c0c400> does not."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "results = cross_val_score(model, X_train, y_train, cv=kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
